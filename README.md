
# BA OOH Ads: An√°lisis de Publicidad Exterior

Proyecto de Data Engineering y An√°lisis Espacial que implementa un pipeline ETL moderno para extraer, procesar y visualizar el impacto de la publicidad en v√≠a p√∫blica en la Ciudad de Buenos Aires.

## üéØ Prop√≥sito del Pipeline

El objetivo principal de este proyecto es migrar un an√°lisis legacy a una arquitectura escalable en Python, capaz de ingerir datos de padrones publicitarios, geolocalizarlos con precisi√≥n y enriquecerlos con contexto urbano (puntos de inter√©s comercial y alcance poblacional). El sistema final alimenta un dashboard interactivo para la toma de decisiones basada en datos espaciales.

Los componentes principales del pipeline son:

* **Extracci√≥n (E):** Consume datos heterog√©neos de m√∫ltiples fuentes:
1. **Padr√≥n de Anuncios:** Datos administrativos del GCBA (CSV).
2. **Entorno Comercial (POIs):** Extracci√≥n de OpenStreetMap via Overpass API (OSMnx).
3. **Demograf√≠a y Movilidad:** Datos del Censo 2022 (INDEC) y viajes en transporte p√∫blico (SUBE) procesados con DuckDB.
4. **Capas Administrativas:** GeoJSONs oficiales de Barrios, Comunas y Zonificaci√≥n.


* **Transformaci√≥n (T):**
* **Geocodificaci√≥n:** Normalizaci√≥n de direcciones y geocoding contra APIs (Photon) con una capa de cach√© persistente en SQLite.
* **Modelado Espacial:** Generaci√≥n de grillas hexagonales **H3** (Uber) para unificar geometr√≠as dispares.
* **Machine Learning:** Detecci√≥n de centralidades comerciales mediante algoritmos de clustering (**DBSCAN**).

* **Consolidaci√≥n:** Integra todas las dimensiones en una estructura columnar optimizada (`.parquet`) lista para ser explotada por el motor de visualizaci√≥n.

## üìÅ Estructura del Repositorio

```text
ba_ooh_ads/
‚îú‚îÄ‚îÄ app/                  # Aplicaci√≥n Web (Shiny for Python)
‚îÇ   ‚îú‚îÄ‚îÄ app.py            # L√≥gica del servidor y UI
‚îÇ   ‚îî‚îÄ‚îÄ components/       # Componentes de UI reutilizables
‚îú‚îÄ‚îÄ data/                 # Vol√∫menes de datos (gestionados por Docker)
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Datos crudos (CSV, YAML)
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Datos transformados (Parquet)
‚îÇ   ‚îú‚îÄ‚îÄ external/         # Capas geogr√°ficas (Barrios, Censo)
‚îÇ   ‚îî‚îÄ‚îÄ cache/            # Bases de datos SQLite (Geocoding, OSM)
‚îú‚îÄ‚îÄ src/                  # C√≥digo fuente del ETL
‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Configuraci√≥n centralizada (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ etl/              # Pipelines de Datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ads/          # Pipeline de Anuncios (Extract, Geocode, Transform)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pois/         # Pipeline de POIs (Clustering DBSCAN)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ population/   # Pipeline de Poblaci√≥n (Censo + H3 Reach)
‚îÇ   ‚îî‚îÄ‚îÄ utils/            # Utilidades espaciales y de logging
‚îú‚îÄ‚îÄ tests/                # Tests unitarios e integraci√≥n
‚îú‚îÄ‚îÄ Dockerfile            # Imagen base (Python 3.11 + uv)
‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestaci√≥n de servicios
‚îî‚îÄ‚îÄ Makefile              # Entrypoints para comandos comunes

```

## üõ† Tech Stack

* **Lenguaje:** Python 3.11
* **Gesti√≥n de Paquetes:** `uv` (Astral)
* **Contenerizaci√≥n:** Docker & Docker Compose
* **Procesamiento:** Pandas, Geopandas, DuckDB (OLAP local), Shapely
* **Espacial:** H3 (Uber), OSMnx, Scikit-learn (DBSCAN)
* **Dashboard:** Shiny for Python, Ipyleaflet
* **Testing:** Pytest, Pytest-mock

## üöÄ Instalaci√≥n y Despliegue con Docker

El proyecto est√° totalmente contenedorizado. Se utiliza `uv` para una gesti√≥n de dependencias r√°pida dentro de la imagen.

1. **Clonar el Repositorio:**
```bash
git clone "https://github.com/tu_usuario/ba_ooh_ads.git"
cd ba_ooh_ads

```

2. **Configurar Variables de Entorno (Opcional):**
El proyecto utiliza `pydantic-settings` en `src/config.py`. Por defecto, los paths son relativos a la ra√≠z del proyecto. Si necesitas cambiar directorios o configurar credenciales futuras, crea un archivo `.env` en la ra√≠z.
3. **Construir y Ejecutar el Pipeline ETL:**
Utilizamos un `Makefile` para simplificar la orquestaci√≥n.
* **Construir la imagen:**
```bash
make build

```

* **Ejecutar el Pipeline Completo:**
Este comando descarga capas administrativas, procesa anuncios (incluyendo geocoding), extrae POIs, calcula clusters y cruza datos censales.
```bash
make etl-full

```

> **Nota:** La primera ejecuci√≥n puede demorar debido a la descarga de datos censales y el proceso de geocodificaci√≥n. Las ejecuciones subsiguientes son r√°pidas gracias al cach√© en SQLite.


* **Ejecutar pasos individuales (Ejemplos):**
```bash
make layers       # Solo capas administrativas
make ads          # Solo padr√≥n de anuncios
make osm_pois     # Solo POIs y Clustering
make popu_reach   # Solo c√°lculo de alcance poblacional

```


4. **Desplegar la Visualizaci√≥n:**
Levanta el servidor de Shiny for Python.
```bash
make up

```

Acced√© al dashboard desde el navegador ingresando en: `http://localhost:8000`


## üß¨ Arquitectura y Flujo de Datos

El sistema integra flujos asincr√≥nicos de datos espaciales que convergen en un dataset consolidado.

### Diagrama de Flujo del Pipeline ETL

```mermaid
flowchart LR
    subgraph Sources["Fuentes de Datos"]
        direction TB
        S_ADS[("Padr√≥n Anuncios<br>(CSV GCBA)")]
        S_OSM[("OpenStreetMap<br>(Overpass API)")]
        S_CENSO[("Censo 2022 + SUBE<br>(S3/DuckDB)")]
        S_ADMIN[("Capas Admin<br>(GeoJSON)")]
    end

    subgraph Processing["Procesamiento & Transformaci√≥n"]
        direction TB
        
        %% Track Anuncios
        GEOCODE("Geocoding Service<br>(Photon + SQLite Cache)")
        SPATIAL_JOIN("Spatial Enirchment<br>(Barrios/Zonificaci√≥n)")
        
        %% Track POIs
        CLUSTERING("DBSCAN Clustering<br>(Global & Tem√°tico)")
        
        %% Track Poblaci√≥n
        H3_GRID("H3 Gridding<br>(Interpolaci√≥n Areal)")
        REACH("Reach Calculation<br>(Residente + Circulante)")
    end

    subgraph Consolidation["Consolidaci√≥n"]
        MERGE{{"Consolidate Ads"}}
        FINAL_DB[("Tablero Consolidado<br>(Parquet)")]
    end

    %% Relaciones
    S_ADS --> GEOCODE --> SPATIAL_JOIN
    S_ADMIN --> SPATIAL_JOIN
    
    S_OSM --> CLUSTERING
    
    S_CENSO --> H3_GRID --> REACH
    
    SPATIAL_JOIN --> MERGE
    CLUSTERING --> MERGE
    REACH --> MERGE
    
    MERGE --> FINAL_DB

    %% Estilos
    classDef source fill:#e1f5fe,stroke:#01579b
    classDef process fill:#fff3e0,stroke:#e65100
    classDef db fill:#e8f5e9,stroke:#2e7d32
    
    class S_ADS,S_OSM,S_CENSO,S_ADMIN source
    class GEOCODE,SPATIAL_JOIN,CLUSTERING,H3_GRID,REACH process
    class FINAL_DB,MERGE db

```

### Descripci√≥n de Scripts Principales

* **`src/etl/ads/geocoding_ads.py`**: Implementa un servicio de geocodificaci√≥n con "cache-aside". Antes de consultar la API externa (Photon), verifica si la direcci√≥n ya existe en una base de datos local SQLite (`geocache.db`), reduciendo dr√°sticamente los tiempos de re-procesamiento.
* **`src/etl/pois/centrality_clustering.py`**: Aplica el algoritmo no supervisado **DBSCAN** sobre los Puntos de Inter√©s (POIs) de OSM. Genera pol√≠gonos (Concave Hulls) que representan zonas comerciales ("clusters") globales y tem√°ticas (ej: polos gastron√≥micos).
* **`src/etl/population/population_reach.py`**: Utiliza **DuckDB** para procesar grandes vol√∫menes de datos censales (residentes) y transaccionales de transporte (circulantes). Interpola estos datos a una grilla hexagonal **H3 (Resoluci√≥n 9)** para estimar la audiencia potencial de cada ubicaci√≥n.
* **`src/etl/ads/consolidate_ads.py`**: Es el paso final del ETL. Cruza los anuncios geolocalizados con los clusters comerciales y m√©tricas de alcance poblacional (K-Ring neighbors) para generar el archivo `tablero_anuncios_consolidado.parquet`.

### Modelo de Datos Consolidado

El archivo final `.parquet` es una tabla desnormalizada ("One Big Table") optimizada para lecturas r√°pidas en el dashboard:

| Campo | Tipo | Descripci√≥n |
| --- | --- | --- |
| `id_anuncio` | Int | Identificador √∫nico del cartel. |
| `lat`, `long` | Float | Coordenadas geogr√°ficas. |
| `full_address` | String | Direcci√≥n normalizada. |
| `tipo`, `clase` | String | Atributos f√≠sicos del cartel (Pantalla, Frontal, etc.). |
| `barrio`, `comuna` | String | Datos administrativos (Spatial Join). |
| `cluster_global` | Int | ID del cluster comercial general al que pertenece. |
| `cluster_tematico` | Int | ID del cluster espec√≠fico (ej: Gastronom√≠a). |
| `total_reach` | Int | Estimaci√≥n de personas (residentes + circulantes) en el √°rea de influencia. |
| `h3_index` | String | √çndice hexagonal H3. |

## üóÉÔ∏è Visualizaci√≥n con Shiny

La aplicaci√≥n (`app/app.py`) consume el parquet consolidado y expone una interfaz reactiva utilizando **Shiny for Python**.

* **Frontend:** Utiliza `ipyleaflet` para renderizado de mapas de alto rendimiento, permitiendo visualizar miles de puntos y pol√≠gonos con clustering din√°mico.
* **Backend:** Utiliza **DuckDB** en memoria para filtrar y agregar datos en tiempo real seg√∫n las interacciones del usuario en el sidebar (filtrado por barrio, tipo de anuncio o categor√≠a comercial).
* **Interactividad:** Al seleccionar un anuncio, un popup despliega el perfil completo del activo, incluyendo su ID y m√©tricas de alcance.

## üß™ Testing

El proyecto cuenta con una suite de pruebas robusta ubicada en `tests/`, ejecutada con `pytest`.

* **Unit Tests (`tests/unit/`):** Validan la l√≥gica aislada. Ej: `test_geocoding_service.py` verifica que el sistema use la cach√© SQLite antes de llamar a la API; `test_spatial.py` valida las funciones de conversi√≥n H3 y joins espaciales.
* **Integration Tests (`tests/integration/`):** Validan flujos completos. Ej: `test_ads_pipeline.py` simula una ejecuci√≥n end-to-end del m√≥dulo de anuncios usando datos mockeados y un sistema de archivos virtual.
* **Ejecuci√≥n:**
```bash
# Ejecutar todos los tests dentro del contenedor
docker-compose run --rm app pytest

```



## üîó Enlaces √ötiles

* **Fuentes de Datos:**
* [BA Data: Padr√≥n de Anuncios](https://www.google.com/search?q=https://data.buenosaires.gob.ar/dataset/padron-anuncios-empadronados)
* [INDEC: Censo Nacional 2022](https://www.indec.gob.ar/indec/web/Nivel4-Tema-2-41-165)
* [Transporte: Viajes SUBE](https://data.buenosaires.gob.ar/dataset/viajes-etapas-transporte-publico)


* **Documentaci√≥n T√©cnica:**
* [H3: Uber‚Äôs Hexagonal Hierarchical Spatial Index](https://h3geo.org/)
* [Shiny for Python](https://shiny.posit.co/py/)
* [OSMnx: Python for Street Networks](https://osmnx.readthedocs.io/)